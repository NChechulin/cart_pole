model_config:
  num_layers: 3
  hidden_size: 128
  nonlinearity: 'relu'
env_config:
  steps_threshold: 1000
training_config:
  gamma: 0.99
  num_steps: 200000
  steps_per_update: 1
  target_update_steps: 100
  max_grad_norm: 5000
  eval_reward_freq: 7500
  eval_reward_repeats: 3
buffer_config:
  buffer_size: 10000
  batch_size: 32
epsilon_generator_config:
  max_epsilon: 1.
  min_epsilon: 0.1
  decay_steps: 100000
optimizer_config:
  class: 'torch.optim.Adam'
  lr: 0.0001
